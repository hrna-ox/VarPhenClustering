Loading and Processing Data...
Data MIMIC successfully loaded for features ['DBP', 'ESI', 'HR', 'RR', 'SBP', 'SPO2', 'TEMP', 'age', 'gender'] and outcomes ['Death', 'Discharge', 'ICU', 'Ward'].
(X, y) shape: (8328, 10, 9), (8328, 4)
Outcome Distribution: Death          26
Discharge    2860
ICU          1321
Ward         4121
dtype: int64
Loading and Training Model for fold 1...
 Logging experiments in exps/DirVRNN/Run_31_2023-08-02_17-59-23/fold_1
batch_loss tensor([98.4920], grad_fn=<MulBackward0>)
batch loss after backward tensor([98.4920], grad_fn=<MulBackward0>)
batch loss item 98.49199676513672
tr_loss before tensor([0.]).0]
tr_loss tensor([98.4920])
batch_loss tensor([98.4997], grad_fn=<MulBackward0>)
batch loss after backward tensor([98.4997], grad_fn=<MulBackward0>)
batch loss item 98.49967956542969
tr_loss before tensor([98.4920])
tr_loss tensor([196.9917])
batch_loss tensor([98.5236], grad_fn=<MulBackward0>)
batch loss after backward tensor([98.5236], grad_fn=<MulBackward0>)
batch loss item 98.52359771728516
tr_loss before tensor([196.9917])
tr_loss tensor([295.5153])
batch_loss tensor([98.4679], grad_fn=<MulBackward0>)
batch loss after backward tensor([98.4679], grad_fn=<MulBackward0>)
batch loss item 98.46792602539062
tr_loss before tensor([295.5153])
tr_loss tensor([393.9832])
batch_loss tensor([98.5854], grad_fn=<MulBackward0>)
batch loss after backward tensor([98.5854], grad_fn=<MulBackward0>)
batch loss item 98.5854263305664
tr_loss before tensor([393.9832])
tr_loss tensor([492.5686])
batch_loss tensor([98.6896], grad_fn=<MulBackward0>)
batch loss after backward tensor([98.6896], grad_fn=<MulBackward0>)
batch loss item 98.68962860107422
tr_loss before tensor([492.5686])
tr_loss tensor([591.2582])
batch_loss tensor([98.6141], grad_fn=<MulBackward0>)
batch loss after backward tensor([98.6141], grad_fn=<MulBackward0>)
batch loss item 98.61405181884766
tr_loss before tensor([591.2582])
tr_loss tensor([689.8723])
batch_loss tensor([98.1499], grad_fn=<MulBackward0>)
batch loss after backward tensor([98.1499], grad_fn=<MulBackward0>)
batch loss item 98.1499252319336
tr_loss before tensor([689.8723])
tr_loss tensor([788.0222])
batch_loss tensor([98.3915], grad_fn=<MulBackward0>)
batch loss after backward tensor([98.3915], grad_fn=<MulBackward0>)
batch loss item 98.39151763916016
tr_loss before tensor([788.0222])
tr_loss tensor([886.4138])
batch_loss tensor([98.6124], grad_fn=<MulBackward0>)
batch loss after backward tensor([98.6124], grad_fn=<MulBackward0>)
batch loss item 98.61241912841797
tr_loss before tensor([886.4138])
tr_loss tensor([985.0262])
batch_loss tensor([98.5820], grad_fn=<MulBackward0>)
batch loss after backward tensor([98.5820], grad_fn=<MulBackward0>)
batch loss item 98.58195495605469
tr_loss before tensor([985.0262])
tr_loss tensor([1083.6082])
batch_loss tensor([98.7416], grad_fn=<MulBackward0>)
batch loss after backward tensor([98.7416], grad_fn=<MulBackward0>)
batch loss item 98.74163818359375
tr_loss before tensor([1083.6082])
tr_loss tensor([1182.3499])
batch_loss tensor([98.5023], grad_fn=<MulBackward0>)
batch loss after backward tensor([98.5023], grad_fn=<MulBackward0>)
batch loss item 98.50228118896484
tr_loss before tensor([1182.3499])
tr_loss tensor([1280.8522])
batch_loss tensor([98.3414], grad_fn=<MulBackward0>)
batch loss after backward tensor([98.3414], grad_fn=<MulBackward0>)
batch loss item 98.34136199951172
tr_loss before tensor([1280.8522])
tr_loss tensor([1379.1935])
batch_loss tensor([98.5523], grad_fn=<MulBackward0>)
Traceback (most recent call last):
  File "/home/ball4537/anaconda3/envs/dirvrnn-env/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/ball4537/anaconda3/envs/dirvrnn-env/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/ball4537/PycharmProjects/VarPhenClustering/src/models/dirvrnn_run.py", line 125, in <module>
    main()
  File "/home/ball4537/PycharmProjects/VarPhenClustering/src/models/dirvrnn_run.py", line 99, in main
    model.fit(train_data=(X_train, y_train), val_data=(X_val, y_val),
  File "/home/ball4537/PycharmProjects/VarPhenClustering/src/models/DirVRNN.py", line 552, in fit
    "Train {} ({:.0f}%):  [loss {:.2f} - loglik {:.2f} - kl {:.2f} - outl {:.2f}]".format(
  File "/home/ball4537/anaconda3/envs/dirvrnn-env/lib/python3.10/site-packages/torch/_tensor.py", line 873, in __format__
    return object.__format__(self, format_spec)
TypeError: unsupported format string passed to Tensor.__format__
batch loss after backward tensor([98.5523], grad_fn=<MulBackward0>)
batch loss item 98.55230712890625
tr_loss before tensor([1379.1935])
tr_loss tensor([1477.7458])
batch_loss tensor([98.6240], grad_fn=<MulBackward0>)
batch loss after backward tensor([98.6240], grad_fn=<MulBackward0>)
batch loss item 98.62403106689453
tr_loss before tensor([1477.7458])
tr_loss tensor([1576.3699])
Epoch Losses
tensor([98.5231])
tensor([-98.8600])
tensor([1.1288])
tensor([1.4657])