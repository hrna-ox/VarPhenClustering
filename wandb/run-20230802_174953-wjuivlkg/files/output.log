Loading and Processing Data...
Data MIMIC successfully loaded for features ['DBP', 'ESI', 'HR', 'RR', 'SBP', 'SPO2', 'TEMP', 'age', 'gender'] and outcomes ['Death', 'Discharge', 'ICU', 'Ward'].
(X, y) shape: (8328, 10, 9), (8328, 4)
Outcome Distribution: Death          26
Discharge    2860
ICU          1321
Ward         4121
dtype: int64
Loading and Training Model for fold 1...
 Logging experiments in exps/DirVRNN/Run_28_2023-08-02_17-49-58/fold_1
ELBO:  tensor([-96.5535], grad_fn=<AddBackward0>)
batch_loss tensor([96.5535], grad_fn=<MulBackward0>)
batch loss after backward tensor([96.5535], grad_fn=<MulBackward0>)
batch loss item 96.55345153808594
tr_loss tensor([96.5535]) 0.0]
ELBO:  tensor([-96.4686], grad_fn=<AddBackward0>)
batch_loss tensor([96.4686], grad_fn=<MulBackward0>)
batch loss after backward tensor([96.4686], grad_fn=<MulBackward0>)
batch loss item 96.4686279296875
tr_loss tensor([193.0221])6.25]
ELBO:  tensor([-96.3379], grad_fn=<AddBackward0>)
batch_loss tensor([96.3379], grad_fn=<MulBackward0>)
batch loss after backward tensor([96.3379], grad_fn=<MulBackward0>)
batch loss item 96.33787536621094
tr_loss tensor([289.3600])12.5]
ELBO:  tensor([-96.8638], grad_fn=<AddBackward0>)
batch_loss tensor([96.8638], grad_fn=<MulBackward0>)
batch loss after backward tensor([96.8638], grad_fn=<MulBackward0>)
batch loss item 96.86382293701172
tr_loss tensor([386.2238])18.75]
ELBO:  tensor([-96.8189], grad_fn=<AddBackward0>)
batch_loss tensor([96.8189], grad_fn=<MulBackward0>)
batch loss after backward tensor([96.8189], grad_fn=<MulBackward0>)
batch loss item 96.81890869140625
tr_loss tensor([483.0427])25.0]
ELBO:  tensor([-96.2031], grad_fn=<AddBackward0>)
batch_loss tensor([96.2031], grad_fn=<MulBackward0>)
batch loss after backward tensor([96.2031], grad_fn=<MulBackward0>)
batch loss item 96.203125
tr_loss tensor([579.2458])31.25]
ELBO:  tensor([-96.3661], grad_fn=<AddBackward0>)
batch_loss tensor([96.3661], grad_fn=<MulBackward0>)
batch loss after backward tensor([96.3661], grad_fn=<MulBackward0>)
batch loss item 96.36613464355469
tr_loss tensor([675.6120])37.5]
ELBO:  tensor([-96.6779], grad_fn=<AddBackward0>)
batch_loss tensor([96.6779], grad_fn=<MulBackward0>)
batch loss after backward tensor([96.6779], grad_fn=<MulBackward0>)
batch loss item 96.67787170410156
tr_loss tensor([772.2899])43.75]
ELBO:  tensor([-96.4253], grad_fn=<AddBackward0>)
batch_loss tensor([96.4253], grad_fn=<MulBackward0>)
batch loss after backward tensor([96.4253], grad_fn=<MulBackward0>)
batch loss item 96.42530822753906
tr_loss tensor([868.7151])50.0]
ELBO:  tensor([-96.5245], grad_fn=<AddBackward0>)
batch_loss tensor([96.5245], grad_fn=<MulBackward0>)
batch loss after backward tensor([96.5245], grad_fn=<MulBackward0>)
batch loss item 96.5245132446289
tr_loss tensor([965.2397])56.25]
ELBO:  tensor([-96.7382], grad_fn=<AddBackward0>)
batch_loss tensor([96.7382], grad_fn=<MulBackward0>)
batch loss after backward tensor([96.7382], grad_fn=<MulBackward0>)
batch loss item 96.73821258544922
tr_loss tensor([1061.9779])2.5]
ELBO:  tensor([-96.9552], grad_fn=<AddBackward0>)
batch_loss tensor([96.9552], grad_fn=<MulBackward0>)
batch loss after backward tensor([96.9552], grad_fn=<MulBackward0>)
batch loss item 96.95515441894531
tr_loss tensor([1158.9331])8.75]
ELBO:  tensor([-96.3124], grad_fn=<AddBackward0>)
batch_loss tensor([96.3124], grad_fn=<MulBackward0>)
batch loss after backward tensor([96.3124], grad_fn=<MulBackward0>)
batch loss item 96.31243896484375
tr_loss tensor([1255.2456])5.0]
ELBO:  tensor([-96.8414], grad_fn=<AddBackward0>)
batch_loss tensor([96.8414], grad_fn=<MulBackward0>)
batch loss after backward tensor([96.8414], grad_fn=<MulBackward0>)
batch loss item 96.84136199951172
tr_loss tensor([1352.0869])1.25]
ELBO:  tensor([-96.3896], grad_fn=<AddBackward0>)
batch_loss tensor([96.3896], grad_fn=<MulBackward0>)
batch loss after backward tensor([96.3896], grad_fn=<MulBackward0>)
batch loss item 96.38960266113281
tr_loss tensor([1448.4766])7.5]
ELBO:  tensor([-96.5828], grad_fn=<AddBackward0>)
batch_loss tensor([96.5828], grad_fn=<MulBackward0>)
batch loss after backward tensor([96.5828], grad_fn=<MulBackward0>)
batch loss item 96.58284759521484
tr_loss tensor([1545.0594])3.75]
epoch loss:  tensor([96.5662])
epoch loglik:  tensor([-99.5931])
epoch kl:  tensor([-1.4743])
epoch outl:  tensor([1.5526])
Traceback (most recent call last):
  File "/home/ball4537/anaconda3/envs/dirvrnn-env/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/ball4537/anaconda3/envs/dirvrnn-env/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/ball4537/PycharmProjects/VarPhenClustering/src/models/dirvrnn_run.py", line 125, in <module>
    main()
  File "/home/ball4537/PycharmProjects/VarPhenClustering/src/models/dirvrnn_run.py", line 99, in main
    model.fit(train_data=(X_train, y_train), val_data=(X_val, y_val),
  File "/home/ball4537/PycharmProjects/VarPhenClustering/src/models/DirVRNN.py", line 552, in fit
    "Train {} ({:.0f}%):  [loss {:.2f} - loglik {:.2f} - kl {:.2f} - outl {:.2f}]".format(
  File "/home/ball4537/anaconda3/envs/dirvrnn-env/lib/python3.10/site-packages/torch/_tensor.py", line 873, in __format__
    return object.__format__(self, format_spec)
TypeError: unsupported format string passed to Tensor.__format__