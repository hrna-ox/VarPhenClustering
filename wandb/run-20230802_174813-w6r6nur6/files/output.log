Loading and Processing Data...
Data MIMIC successfully loaded for features ['DBP', 'ESI', 'HR', 'RR', 'SBP', 'SPO2', 'TEMP', 'age', 'gender'] and outcomes ['Death', 'Discharge', 'ICU', 'Ward'].
(X, y) shape: (8328, 10, 9), (8328, 4)
Outcome Distribution: Death          26
Discharge    2860
ICU          1321
Ward         4121
dtype: int64
Loading and Training Model for fold 1...
 Logging experiments in exps/DirVRNN/Run_26_2023-08-02_17-48-18/fold_1
ELBO:  tensor([-101.1809], grad_fn=<AddBackward0>)
batch_loss tensor([101.1809], grad_fn=<MulBackward0>)
batch loss after backward tensor([101.1809], grad_fn=<MulBackward0>)
batch loss after backward with single output tensor(101.1809, grad_fn=<SelectBackward0>)
tr_loss tensor([101.1809]) 0.0]
ELBO:  tensor([-101.0611], grad_fn=<AddBackward0>)
batch_loss tensor([101.0611], grad_fn=<MulBackward0>)
batch loss after backward tensor([101.0611], grad_fn=<MulBackward0>)
batch loss after backward with single output tensor(101.0611, grad_fn=<SelectBackward0>)
tr_loss tensor([202.2420]) 6.25]
ELBO:  tensor([-101.5884], grad_fn=<AddBackward0>)
batch_loss tensor([101.5884], grad_fn=<MulBackward0>)
batch loss after backward tensor([101.5884], grad_fn=<MulBackward0>)
batch loss after backward with single output tensor(101.5884, grad_fn=<SelectBackward0>)
tr_loss tensor([303.8304]) 12.5]
ELBO:  tensor([-101.3151], grad_fn=<AddBackward0>)
batch_loss tensor([101.3151], grad_fn=<MulBackward0>)
batch loss after backward tensor([101.3151], grad_fn=<MulBackward0>)
batch loss after backward with single output tensor(101.3151, grad_fn=<SelectBackward0>)
tr_loss tensor([405.1454]) 18.75]
ELBO:  tensor([-101.1081], grad_fn=<AddBackward0>)
batch_loss tensor([101.1081], grad_fn=<MulBackward0>)
batch loss after backward tensor([101.1081], grad_fn=<MulBackward0>)
batch loss after backward with single output tensor(101.1081, grad_fn=<SelectBackward0>)
tr_loss tensor([506.2535]) 25.0]
ELBO:  tensor([-101.3237], grad_fn=<AddBackward0>)
batch_loss tensor([101.3237], grad_fn=<MulBackward0>)
batch loss after backward tensor([101.3237], grad_fn=<MulBackward0>)
batch loss after backward with single output tensor(101.3237, grad_fn=<SelectBackward0>)
tr_loss tensor([607.5773]) 31.25]
ELBO:  tensor([-101.2785], grad_fn=<AddBackward0>)
batch_loss tensor([101.2785], grad_fn=<MulBackward0>)
batch loss after backward tensor([101.2785], grad_fn=<MulBackward0>)
batch loss after backward with single output tensor(101.2785, grad_fn=<SelectBackward0>)
tr_loss tensor([708.8557]) 37.5]
ELBO:  tensor([-101.1688], grad_fn=<AddBackward0>)
batch_loss tensor([101.1688], grad_fn=<MulBackward0>)
batch loss after backward tensor([101.1688], grad_fn=<MulBackward0>)
batch loss after backward with single output tensor(101.1688, grad_fn=<SelectBackward0>)
tr_loss tensor([810.0245]) 43.75]
ELBO:  tensor([-101.0973], grad_fn=<AddBackward0>)
batch_loss tensor([101.0973], grad_fn=<MulBackward0>)
batch loss after backward tensor([101.0973], grad_fn=<MulBackward0>)
batch loss after backward with single output tensor(101.0973, grad_fn=<SelectBackward0>)
tr_loss tensor([911.1218]) 50.0]
ELBO:  tensor([-101.4017], grad_fn=<AddBackward0>)
batch_loss tensor([101.4017], grad_fn=<MulBackward0>)
batch loss after backward tensor([101.4017], grad_fn=<MulBackward0>)
batch loss after backward with single output tensor(101.4017, grad_fn=<SelectBackward0>)
tr_loss tensor([1012.5235])56.25]
ELBO:  tensor([-101.5385], grad_fn=<AddBackward0>)
batch_loss tensor([101.5385], grad_fn=<MulBackward0>)
batch loss after backward tensor([101.5385], grad_fn=<MulBackward0>)
batch loss after backward with single output tensor(101.5385, grad_fn=<SelectBackward0>)
tr_loss tensor([1114.0620])62.5]
ELBO:  tensor([-101.2966], grad_fn=<AddBackward0>)
batch_loss tensor([101.2966], grad_fn=<MulBackward0>)
batch loss after backward tensor([101.2966], grad_fn=<MulBackward0>)
batch loss after backward with single output tensor(101.2966, grad_fn=<SelectBackward0>)
tr_loss tensor([1215.3586])68.75]
ELBO:  tensor([-100.8938], grad_fn=<AddBackward0>)
batch_loss tensor([100.8938], grad_fn=<MulBackward0>)
batch loss after backward tensor([100.8938], grad_fn=<MulBackward0>)
batch loss after backward with single output tensor(100.8938, grad_fn=<SelectBackward0>)
tr_loss tensor([1316.2524])75.0]
ELBO:  tensor([-101.1541], grad_fn=<AddBackward0>)
batch_loss tensor([101.1541], grad_fn=<MulBackward0>)
batch loss after backward tensor([101.1541], grad_fn=<MulBackward0>)
batch loss after backward with single output tensor(101.1541, grad_fn=<SelectBackward0>)
tr_loss tensor([1417.4065])81.25]
ELBO:  tensor([-101.1038], grad_fn=<AddBackward0>)
batch_loss tensor([101.1038], grad_fn=<MulBackward0>)
Traceback (most recent call last):
  File "/home/ball4537/anaconda3/envs/dirvrnn-env/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/ball4537/anaconda3/envs/dirvrnn-env/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/ball4537/PycharmProjects/VarPhenClustering/src/models/dirvrnn_run.py", line 125, in <module>
    main()
  File "/home/ball4537/PycharmProjects/VarPhenClustering/src/models/dirvrnn_run.py", line 99, in main
    model.fit(train_data=(X_train, y_train), val_data=(X_val, y_val),
  File "/home/ball4537/PycharmProjects/VarPhenClustering/src/models/DirVRNN.py", line 552, in fit
    "Train {} ({:.0f}%):  [loss {:.2f} - loglik {:.2f} - kl {:.2f} - outl {:.2f}]".format(
  File "/home/ball4537/anaconda3/envs/dirvrnn-env/lib/python3.10/site-packages/torch/_tensor.py", line 873, in __format__
    return object.__format__(self, format_spec)
TypeError: unsupported format string passed to Tensor.__format__
batch loss after backward tensor([101.1038], grad_fn=<MulBackward0>)
batch loss after backward with single output tensor(101.1038, grad_fn=<SelectBackward0>)
tr_loss tensor([1518.5103])87.5]
ELBO:  tensor([-101.2110], grad_fn=<AddBackward0>)
batch_loss tensor([101.2110], grad_fn=<MulBackward0>)
batch loss after backward tensor([101.2110], grad_fn=<MulBackward0>)
batch loss after backward with single output tensor(101.2110, grad_fn=<SelectBackward0>)
tr_loss tensor([1619.7213])93.75]
epoch loss:  tensor([101.2326])
epoch loglik:  tensor([-99.9438])
epoch kl:  tensor([2.7418])
epoch outl:  tensor([1.4530])