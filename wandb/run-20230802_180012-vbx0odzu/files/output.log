Loading and Processing Data...
Data MIMIC successfully loaded for features ['DBP', 'ESI', 'HR', 'RR', 'SBP', 'SPO2', 'TEMP', 'age', 'gender'] and outcomes ['Death', 'Discharge', 'ICU', 'Ward'].
(X, y) shape: (8328, 10, 9), (8328, 4)
Outcome Distribution: Death          26
Discharge    2860
ICU          1321
Ward         4121
dtype: int64
Loading and Training Model for fold 1...
 Logging experiments in exps/DirVRNN/Run_32_2023-08-02_18-00-17/fold_1
batch_loss tensor([99.5061], grad_fn=<MulBackward0>)
batch loss after backward tensor([99.5061], grad_fn=<MulBackward0>)
batch loss item 99.50605010986328
tr_loss before tensor([0.]).0]
tr_loss tensor([99.5061])
batch_loss tensor([99.5139], grad_fn=<MulBackward0>)
batch loss after backward tensor([99.5139], grad_fn=<MulBackward0>)
batch loss item 99.51387023925781
tr_loss before tensor([99.5061])
tr_loss tensor([199.0199])
batch_loss tensor([99.1487], grad_fn=<MulBackward0>)
batch loss after backward tensor([99.1487], grad_fn=<MulBackward0>)
batch loss item 99.148681640625
tr_loss before tensor([199.0199])
tr_loss tensor([298.1686])
batch_loss tensor([99.1881], grad_fn=<MulBackward0>)
batch loss after backward tensor([99.1881], grad_fn=<MulBackward0>)
batch loss item 99.18814086914062
tr_loss before tensor([298.1686])
tr_loss tensor([397.3568])
batch_loss tensor([99.3648], grad_fn=<MulBackward0>)
batch loss after backward tensor([99.3648], grad_fn=<MulBackward0>)
batch loss item 99.36476135253906
tr_loss before tensor([397.3568])
tr_loss tensor([496.7215])
batch_loss tensor([99.5795], grad_fn=<MulBackward0>)
batch loss after backward tensor([99.5795], grad_fn=<MulBackward0>)
batch loss item 99.57949829101562
tr_loss before tensor([496.7215])
tr_loss tensor([596.3010])
batch_loss tensor([99.6044], grad_fn=<MulBackward0>)
batch loss after backward tensor([99.6044], grad_fn=<MulBackward0>)
batch loss item 99.60441589355469
tr_loss before tensor([596.3010])
tr_loss tensor([695.9055])
batch_loss tensor([99.5229], grad_fn=<MulBackward0>)
batch loss after backward tensor([99.5229], grad_fn=<MulBackward0>)
batch loss item 99.52288055419922
tr_loss before tensor([695.9055])
tr_loss tensor([795.4283])
batch_loss tensor([99.3542], grad_fn=<MulBackward0>)
batch loss after backward tensor([99.3542], grad_fn=<MulBackward0>)
batch loss item 99.35417175292969
tr_loss before tensor([795.4283])
tr_loss tensor([894.7825])
batch_loss tensor([99.1772], grad_fn=<MulBackward0>)
batch loss after backward tensor([99.1772], grad_fn=<MulBackward0>)
batch loss item 99.17720794677734
tr_loss before tensor([894.7825])
tr_loss tensor([993.9597])
batch_loss tensor([99.2733], grad_fn=<MulBackward0>)
batch loss after backward tensor([99.2733], grad_fn=<MulBackward0>)
batch loss item 99.27325439453125
tr_loss before tensor([993.9597])
tr_loss tensor([1093.2329])
batch_loss tensor([99.1700], grad_fn=<MulBackward0>)
batch loss after backward tensor([99.1700], grad_fn=<MulBackward0>)
batch loss item 99.16995239257812
tr_loss before tensor([1093.2329])
tr_loss tensor([1192.4028])
batch_loss tensor([99.0580], grad_fn=<MulBackward0>)
batch loss after backward tensor([99.0580], grad_fn=<MulBackward0>)
batch loss item 99.0580062866211
tr_loss before tensor([1192.4028])
tr_loss tensor([1291.4608])
batch_loss tensor([99.3618], grad_fn=<MulBackward0>)
batch loss after backward tensor([99.3618], grad_fn=<MulBackward0>)
batch loss item 99.36175537109375
tr_loss before tensor([1291.4608])
tr_loss tensor([1390.8225])
batch_loss tensor([99.6401], grad_fn=<MulBackward0>)
Traceback (most recent call last):
  File "/home/ball4537/anaconda3/envs/dirvrnn-env/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/ball4537/anaconda3/envs/dirvrnn-env/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/ball4537/PycharmProjects/VarPhenClustering/src/models/dirvrnn_run.py", line 125, in <module>
    main()
  File "/home/ball4537/PycharmProjects/VarPhenClustering/src/models/dirvrnn_run.py", line 99, in main
    model.fit(train_data=(X_train, y_train), val_data=(X_val, y_val),
  File "/home/ball4537/PycharmProjects/VarPhenClustering/src/models/DirVRNN.py", line 552, in fit
    "Train {} ({:.0f}%):  [loss {:.2f} - loglik {:.2f} - kl {:.2f} - outl {:.2f}]".format(
TypeError: unsupported format string passed to numpy.ndarray.__format__
batch loss after backward tensor([99.6401], grad_fn=<MulBackward0>)
batch loss item 99.64012145996094
tr_loss before tensor([1390.8225])
tr_loss tensor([1490.4626])
batch_loss tensor([99.5306], grad_fn=<MulBackward0>)
batch loss after backward tensor([99.5306], grad_fn=<MulBackward0>)
batch loss item 99.5306396484375
tr_loss before tensor([1490.4626])
tr_loss tensor([1589.9933])
Epoch Losses
tensor([99.3746])
tensor([-98.1867])
tensor([2.6307])
tensor([1.4428])