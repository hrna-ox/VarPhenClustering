{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afe22435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.data_processing.data_loader import data_loader\n",
    "import src.training.training_utils as training_utils\n",
    "# from src.results.main import evaluate\n",
    "# import src.visualisation.main as vis_main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b86d951",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"src/training/run_config.json\", \"r\") as f:\n",
    "    run_config = json.load(f)\n",
    "    f.close()\n",
    "\n",
    "# Extract info\n",
    "data_config = run_config[\"data_config\"]\n",
    "model_config = run_config[\"model_config\"]\n",
    "training_config = run_config[\"training_config\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b8c9a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_config': {'data_name': 'MIMIC', 'target_window': 48, 'feat_set': 'vit-sta', 'time_range': [0, 10], 'train_test_ratio': 0.6, 'train_val_ratio': 0.4, 'seed': 2323}, 'model_config': {'model_name': 'DirVRNN', 'latent_size': 10, 'gate_layers': 2, 'gate_nodes': 20, 'feat_extr_layers': 2, 'feat_extr_nodes': 20, 'num_clus': 6}, 'training_config': {'lr': 0.001, 'epochs': 5, 'bs': 128}}\n"
     ]
    }
   ],
   "source": [
    "print(run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d6749d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.data_processing.data_loader' from 'c:\\\\Users\\\\hruia\\\\PycharmProjects\\\\VarPhenClustering\\\\src\\\\data_processing\\\\data_loader.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import src.data_processing.data_loader as loader\n",
    "reload(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2290cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info = loader.data_loader(**data_config);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "a900d40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.Dir_VRNN import Dir_VRNN_train as model_train\n",
    "from src.models.Dir_VRNN import model as model\n",
    "from src.models.Dir_VRNN import Dir_VRNN_utils as model_utils\n",
    "\n",
    "reload(model_train);\n",
    "reload(model);\n",
    "reload(model_utils);\n",
    "\n",
    "run_config[\"training_config\"][\"bs\"] = 128\n",
    "run_config[\"training_config\"][\"epochs\"] = 20\n",
    "run_config[\"model_config\"][\"num_clus\"] = 3\n",
    "model = model_train.DirVRNN(data_info = data_info, model_config=model_config, training_config=training_config);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0624d9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.models.Dir_VRNN.model as FileModel\n",
    "reload(FileModel)\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_val, X_test = data_info[\"X\"]\n",
    "y_train, y_val, y_test = data_info[\"y\"]\n",
    "\n",
    "# Define parameters\n",
    "i_size = X_train.shape[-1]\n",
    "o_size = y_train.shape[-1]\n",
    "w_size = 3\n",
    "model = FileModel.BaseModel(i_size =i_size, o_size=o_size, w_size=w_size, K=6, l_size=64, gate_hidden=1, gate_hidden_n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "44ca3bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch: 1   [1837264.41912 - 100%]\n",
      "Val epoch: 1   [1312438.37500 - 0%]\n",
      "Train epoch: 2   [774340.64338 - 100%]\n",
      "Val epoch: 2   [95147.15625 - 0%]\n",
      "Train epoch: 3   [16349.21591 - 100%]\n",
      "Val epoch: 3   [-423.29688 - 0%]\n",
      "Train epoch: 4   [-430.82109 - 100%]\n",
      "Val epoch: 4   [-439.46552 - 0%]\n",
      "Train epoch: 5   [-446.51093 - 100%]\n",
      "Val epoch: 5   [-455.92923 - 0%]\n",
      "Train epoch: 6   [-478.51230 - 100%]\n",
      "Val epoch: 6   [-578.17712 - 0%]\n",
      "Train epoch: 7   [-621.24868 - 100%]\n",
      "Val epoch: 7   [-642.68951 - 0%]\n",
      "Train epoch: 8   [-650.71106 - 100%]\n",
      "Val epoch: 8   [-658.13068 - 0%]\n",
      "Train epoch: 9   [-663.30345 - 100%]\n",
      "Val epoch: 9   [-667.90851 - 0%]\n",
      "Train epoch: 10   [-671.20017 - 100%]\n",
      "Val epoch: 10   [-674.07709 - 0%]\n",
      "Train epoch: 11   [-675.67582 - 100%]\n",
      "Val epoch: 11   [-676.95667 - 0%]\n",
      "Train epoch: 12   [-677.45951 - 100%]\n",
      "Val epoch: 12   [-677.80994 - 0%]\n",
      "Train epoch: 13   [-678.00172 - 100%]\n",
      "Val epoch: 13   [-678.22363 - 0%]\n",
      "Train epoch: 14   [-678.41031 - 100%]\n",
      "Val epoch: 14   [-678.57233 - 0%]\n",
      "Train epoch: 15   [-678.76255 - 100%]\n",
      "Val epoch: 15   [-678.91174 - 0%]\n",
      "Train epoch: 16   [-679.09213 - 100%]\n",
      "Val epoch: 16   [-679.22302 - 0%]\n",
      "Train epoch: 17   [-679.42022 - 100%]\n",
      "Val epoch: 17   [-679.56909 - 0%]\n",
      "Train epoch: 18   [-679.71466 - 100%]\n",
      "Val epoch: 18   [-679.81116 - 0%]\n",
      "Train epoch: 19   [-679.96325 - 100%]\n",
      "Val epoch: 19   [-680.02954 - 0%]\n",
      "Train epoch: 20   [-680.16509 - 100%]\n",
      "Val epoch: 20   [-680.22778 - 0%]\n"
     ]
    }
   ],
   "source": [
    "# Prepare experiment\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Compute dimensionality of input and output\n",
    "input_size = X_train.shape[-1]\n",
    "outcome_size = y_train.shape[-1]\n",
    "batch_size=32\n",
    "\n",
    "# Prepare data for training\n",
    "train_dataset = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
    "val_dataset = TensorDataset(torch.from_numpy(X_val), torch.from_numpy(y_val))\n",
    "\n",
    "self.train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "self.val_loader = DataLoader(val_dataset, batch_size=X_val.shape[0])\n",
    "\n",
    "# Prepare data for evaluating\n",
    "test_dataset = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n",
    "self.test_loader = DataLoader(test_dataset, batch_size=X_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "2abbec30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [-1133.16125 - 0%]\n",
      "dict_keys(['alpha_prior', 'alpha_enc', 'est_pi', 'est_cluster_means', 'est_outcomes', 'est_gen_mean', 'est_gen_data', 'cell_state', 'pred_loss', 'y_pred', 'X', 'y'])\n"
     ]
    }
   ],
   "source": [
    " \n",
    "    \n",
    "# Predict model\n",
    "X_test, y_test = data_info[\"X\"][-1], data_info[\"y\"][-1]\n",
    "history = model.predict(X_test, y_test)\n",
    "     \n",
    "# Print available keys\n",
    "print(history.keys())\n",
    "             \n",
    "                 \n",
    "                     \n",
    "                         \n",
    "                             \n",
    "                                 \n",
    "                                     \n",
    "                                         \n",
    "                                             \n",
    "                                                 \n",
    "                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "9d7c045c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3565, 10, 6])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history[\"est_pi\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "7dd614ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = history[\"est_pi\"][:, -1, :]\n",
    "clus_one_hot = [torch.argmax(test, axis=1).detach().numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "f578e9e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,  92., 608.,  91.],\n",
       "       [  2.,  94., 540.,  62.],\n",
       "       [  0.,  89., 530.,  72.],\n",
       "       [  0.,   0.,   0.,   0.],\n",
       "       [  1.,  98., 522.,  79.],\n",
       "       [  0.,  80., 514.,  90.]])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(np.transpose(clus_one_hot), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "79b77d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3198, 0.6802],\n",
       "        [0.3029, 0.6971],\n",
       "        [0.3031, 0.6969],\n",
       "        [0.3030, 0.6970],\n",
       "        [0.3031, 0.6969],\n",
       "        [0.3031, 0.6969],\n",
       "        [0.3031, 0.6969],\n",
       "        [0.3030, 0.6970],\n",
       "        [0.3030, 0.6970],\n",
       "        [0.3030, 0.6970]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "history[\"alpha_enc\"][0, :, :] / torch.sum(history[\"alpha_enc\"][0, :, :], dim=-1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b4186f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3194, 0.6806],\n",
       "        [0.3027, 0.6973],\n",
       "        [0.3031, 0.6969],\n",
       "        [0.3030, 0.6970],\n",
       "        [0.3031, 0.6969],\n",
       "        [0.3032, 0.6968],\n",
       "        [0.3020, 0.6980],\n",
       "        [0.3020, 0.6980],\n",
       "        [0.3020, 0.6980],\n",
       "        [0.3020, 0.6980]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history[\"alpha_enc\"][101, :, :] / torch.sum(history[\"alpha_enc\"][101, :, :], dim=-1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "450ad7f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.min(\n",
       "values=tensor([[0.3029, 0.6802],\n",
       "        [0.3025, 0.6785],\n",
       "        [0.3039, 0.6778],\n",
       "        ...,\n",
       "        [0.3020, 0.6792],\n",
       "        [0.3020, 0.6800],\n",
       "        [0.3014, 0.6812]], grad_fn=<MinBackward0>),\n",
       "indices=tensor([[1, 0],\n",
       "        [3, 0],\n",
       "        [1, 0],\n",
       "        ...,\n",
       "        [8, 0],\n",
       "        [8, 0],\n",
       "        [8, 0]]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.min(history[\"est_pi\"], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8633d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
