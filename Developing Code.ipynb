{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1604e617",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import Libraries\n",
    "import datetime as dt\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import src.data_processing.MIMIC.test_functions as tests\n",
    "\n",
    "# LOAD CONFIGURATION \n",
    "with open(\"src/data_processing/MIMIC/MIMIC_PROCESSING_DEFAULT_VARS.json\", \"r\") as f:\n",
    "    DEFAULT_CONFIG = json.load(f)\n",
    "    f.close()\n",
    "\n",
    "if not os.path.exists(DEFAULT_CONFIG[\"SAVE_FD\"]):\n",
    "    os.makedirs(DEFAULT_CONFIG[\"SAVE_FD\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "284b2e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    assert os.path.exists(DEFAULT_CONFIG[\"SAVE_FD\"] + \"admissions_intermediate.csv\")\n",
    "    assert os.path.exists(DEFAULT_CONFIG[\"SAVE_FD\"] + \"vitals_intermediate.csv\")\n",
    "\n",
    "except AssertionError as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06de2ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Information\n",
    "print(\"\\n\\n ======== PROCESSING OUTCOMES ======== \\n\\n\")\n",
    "\n",
    "# Load previously processed data\n",
    "adm_proc = pd.read_csv(\n",
    "    DEFAULT_CONFIG[\"SAVE_FD\"] + \"admissions_intermediate.csv\",\n",
    "    index_col=0, \n",
    "    header=0, \n",
    "    parse_dates=[\"intime\", \"outtime\", \"intime_next\", \"outtime_next\", \"deathtime\"]\n",
    ")\n",
    "vit_proc = (\n",
    "    pd.read_csv(\n",
    "    DEFAULT_CONFIG[\"SAVE_FD\"] + \"vitals_intermediate.csv\", \n",
    "    index_col=0, \n",
    "    header=0, \n",
    "    parse_dates=DEFAULT_CONFIG[\"VITALS_TIME_VARS\"]\n",
    "    )\n",
    "    .reset_index(drop=False)\n",
    "    .assign(sampled_time_to_end=lambda x: pd.to_timedelta(x[\"sampled_time_to_end\"]))  # pd does not load timedelta automatically\n",
    ")\n",
    "\n",
    "\n",
    "# Check correct computation of admissions and vitals\n",
    "tests.test_admissions_processed_correctly(adm_proc)\n",
    "tests.test_vitals_processed_correctly(vit_proc, config_dic=DEFAULT_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e546c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load core info\n",
    "transfers_core = pd.read_csv(\n",
    "    DEFAULT_CONFIG[\"DATA_FD\"] + \"core/transfers.csv\", \n",
    "    index_col=None, \n",
    "    header=0, \n",
    "    parse_dates=[\"intime\", \"outtime\"]\n",
    ")\n",
    "admissions_core = pd.read_csv(\n",
    "    DEFAULT_CONFIG[\"DATA_FD\"] + \"core/admissions.csv\",\n",
    "    index_col=None,\n",
    "    header=0,\n",
    "    parse_dates=[\"admittime\", \"dischtime\", \"deathtime\", \"edregtime\", \"edouttime\"]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2084ce48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing ('subject_id', 'hadm_id', 'stay_id') are subset of cohort data.\n",
      "Test passed!\n",
      "\n",
      "Testing ids are complete for params ('subject_id', 'hadm_id', 'stay_id', 'stay_id')\n",
      "Test passed for variable subject_id!\n",
      "Test passed for variable hadm_id!\n",
      "Test passed for variable stay_id!\n",
      "Test passed for variable stay_id!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Step 1: Subset the set of transfers/admissions_core to the already processed cohort.\n",
    "\n",
    "We do this by merging. \n",
    "\"\"\"\n",
    "\n",
    "# Define Id for merging. We separate deathtime as one database registers only date, while the other\n",
    "# registers everyting (i.e. up to second)\n",
    "# tr_merge_ids = [\n",
    "#     col for \n",
    "#     col in vit_proc.columns.tolist() if\n",
    "#     col in transfers_core.columns.tolist() and\n",
    "#     \"death\" not in col\n",
    "# ]\n",
    "hadm_merge_ids = [\n",
    "    col for\n",
    "    col in vit_proc.columns.tolist() if\n",
    "    col in admissions_core.columns.tolist() and\n",
    "    \"death\" not in col\n",
    "]\n",
    "merge_ids = [\"subject_id\", \"hadm_id\", \"stay_id\"]         # Useful simplication\n",
    "\n",
    "# # Inner merge for transfers core\n",
    "# transfers_S1 = (\n",
    "#     transfers_core\n",
    "#     .merge(\n",
    "#         vit_proc.drop_duplicates(subset=merge_ids),   # Drop duplicates as we don't need all the rows\n",
    "#         how=\"inner\",\n",
    "#         on=tr_merge_ids\n",
    "#     )\n",
    "#     .dropna(subset=[\"hadm_id\"])                 # Drop rows with no hadm_id as we can't compare with transfers\n",
    "#     .sort_values(by=merge_ids, ascending=True) # Sort by subject_id and stay_id\n",
    "# )\n",
    "\n",
    "# Inner merge for admissions core\n",
    "admissions_S1 = (\n",
    "    admissions_core\n",
    "    .merge(\n",
    "        vit_proc.drop_duplicates(subset=merge_ids), # only want one obvs per admission for merging\n",
    "        how=\"inner\",\n",
    "        on=hadm_merge_ids,\n",
    "        suffixes=(\"\", \"_ed\")\n",
    "    )\n",
    "    .dropna(subset=[\"hadm_id\"])            # Drop rows with no hadm_id as we can't compare with transfers\n",
    "    .sort_values(by=merge_ids, ascending=True) # Sort by subject_id and stay_id\n",
    ")\n",
    "\n",
    "# Testing and save\n",
    "# tests.test_ids_subset_of_cohort(transfers_S1, vit_proc, *merge_ids)\n",
    "tests.test_ids_subset_of_cohort(admissions_S1, vit_proc, *merge_ids)\n",
    "# tests.test_is_complete_ids(transfers_S1, *merge_ids, \"stay_id\")\n",
    "tests.test_is_complete_ids(admissions_S1, *merge_ids, \"stay_id\")\n",
    "\n",
    "# Check processing and correctdeness\n",
    "# transfers_S1.to_csv(DEFAULT_CONFIG[\"SAVE_FD\"] + \"transfers_S1.csv\", header=True, index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f332b6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "admissions_S2 = (\n",
    "    admissions_S1\n",
    "    .query(\"intime <= admittime\")                            # admissions to hospital after ED admissions\n",
    "    .query(\"intime_next >= admittime | intime_next.isna()\")  # admissions to hospital before next ED transfer\n",
    "    .query(\"outtime <= edouttime\")                           # transfer outtime before ed exit time\n",
    "    .query(\"intime <= edregtime\")                            # transfer intmie before ed registration time\n",
    "    .query(\"dischtime - outtime_next >= @pd.Timedelta('-6h') | outtime_next.isna()\")\n",
    "    # discharge time not earlier than outtime_next (added -6 hours due to some potential delays)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e063f796",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _select_outcome(vitals, transfers, window):\n",
    "    \"\"\"\n",
    "    Determine outcome of admission given dataset with vital and static information, \n",
    "    and data for transfers.\n",
    "    output order is [D, I, W, Disc].\n",
    "    \"\"\"\n",
    "\n",
    "    # Load static information from vitals\n",
    "    try:\n",
    "        ed_outtime, dod = vitals[[\"outtime\", \"deathtime\"]].iloc[0, :]\n",
    "    except IndexError:\n",
    "        ed_outtime, dod = vitals[[\"outtime\", \"deathtime\"]].iloc[:]\n",
    "    \n",
    "\n",
    "    # Check deathtime first\n",
    "    if dod != np.nan:\n",
    "        \n",
    "        # Get time to death\n",
    "        time_to_death = dod - ed_outtime\n",
    "        if time_to_death <= window:\n",
    "            return [1, 0, 0, 0]       \n",
    "        \n",
    "    # If there is no death, or patient died after time window\n",
    "    lower_bound, upper_bound = ed_outtime, ed_outtime + window\n",
    "    transfers_within_window = (\n",
    "        transfers\n",
    "        .query(\"intime >= @lower_bound\")\n",
    "        .query(\"intime <= @upper_bound\")\n",
    "    )\n",
    "    \n",
    "    # Identify ICUs\n",
    "    has_icus = (\n",
    "        transfers_within_window.careunit.str.contains(\"(?i)ICU\", na=False) |\n",
    "        transfers_within_window.careunit.str.contains(\"(?i)Neuro Stepdown\", na=False)\n",
    "    )\n",
    "\n",
    "    # If ICU admission\n",
    "    if has_icus.sum() > 0:\n",
    "        return [0, 1, 0, 0]\n",
    "    \n",
    "    # Check to see transfers contain discharge\n",
    "    has_discharge = transfers_within_window.eventtype.str.contains(\"discharge\", na=False)\n",
    "    if has_discharge.sum() > 0:\n",
    "        return [0, 0, 0, 1]\n",
    "    \n",
    "    else:\n",
    "        return [0, 0, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "78a635ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _test(x):\n",
    "    return type(x)\n",
    "\n",
    "# Compute outcome\n",
    "test = (\n",
    "    admissions_S2\n",
    "    .assign(outcome_24h=)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ebffbe64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1869    NaN\n",
       "3294    NaN\n",
       "5413    NaN\n",
       "2565    NaN\n",
       "2857    NaN\n",
       "       ... \n",
       "85      NaN\n",
       "4740    NaN\n",
       "4901    NaN\n",
       "5547    NaN\n",
       "3900    NaN\n",
       "Name: outcome_24h, Length: 8140, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.outcome_24h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4495601f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
